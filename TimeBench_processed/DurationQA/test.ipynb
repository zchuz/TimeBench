{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "sys.path.append('../utils/')\n",
    "from utils import gpt_decoder, load_json, load_jsonl\n",
    "def write(fp, line):\n",
    "    with open(fp, 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"You need to answer the following question about the duration of the event based on the context.\n",
    "You must choose all correct options.\n",
    "Context: {}\n",
    "Question: {}\n",
    "Options:\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = \"\"\"According to the context, answer the questions and select all correct options.\n",
    "\n",
    "Context: {}\n",
    "Question: {}\n",
    "Options:\n",
    "{}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt3 = \"\"\"There is a question about the commonsense knowledge of event duration.\n",
    "You should answer the questions based on the context and select all correct options.\n",
    "\n",
    "Context: {}\n",
    "Question: {}\n",
    "Options:\n",
    "{}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt4 = \"\"\"There is a question about the commonsense knowledge of event duration.\n",
    "You should answer the questions based on the context and select all correct options.\n",
    "After each chosen option, explain why you choose it.\n",
    "\n",
    "Context: {}\n",
    "Question: {}\n",
    "Options:\n",
    "{}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = load_jsonl('./durationqa_f2_timebench.jsonl')\n",
    "def convert_options_to_options(options):\n",
    "    return '\\n'.join([chr(ord('A') + i) + '. ' + o for i, o in enumerate(options)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The correct options are:\\nF. 10 months\\nG. several days'],\n",
       " ['for years',\n",
       "  'several years',\n",
       "  '8 years',\n",
       "  '22 weeks',\n",
       "  '6 days',\n",
       "  '16 hours',\n",
       "  '8 hours'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n =2\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "gpt_decoder(prompt1.format(c, q, o)), datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Based on the context, the correct options would be:\\n\\nA. several years\\nC. 8 months\\nE. a few days'],\n",
       " 'There is a question about the commonsense knowledge of event duration.\\nYou should answer the questions based on the context and select all correct options.\\n\\nContext: We could certainly slow the aging process down if it had to work its way through Congress .\\nQuestion: How long did it take for it to work its way?\\nOptions:\\nA. several years\\nB. 1 year\\nC. 8 months\\nD. several days\\nE. a few days\\nF. for hours\\nG. 2 days\\nAnswer:\\n',\n",
       " ['several years',\n",
       "  '1 year',\n",
       "  '8 months',\n",
       "  'several days',\n",
       "  'a few days',\n",
       "  'for hours',\n",
       "  '2 days'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 15\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt3.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A. ', 'C. ', 'E. ', 'L. ']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "answer = 'Based on the context, the correct options would be:\\n\\nA. several years\\nC. 8 months\\nE. a few days'\n",
    "\n",
    "re.findall(r'([A-Z]\\.\\s)', answer + ' L. ED.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The correct answers are A. several years and C. 8 months.\\n\\nExplanation:\\nBased on the context, \"if it had to work its way through Congress,\" it implies that the process of working its way through Congress is a lengthy one. Congress is known for its slow decision-making process, so it is reasonable to assume that it would take several years or at least several months for it to work its way through. Therefore, options A. several years and C. 8 months are the correct answers.'],\n",
       " 'There is a question about the commonsense knowledge of event duration.\\nYou should answer the questions based on the context and select all correct options.\\nAfter each chosen option, explain why you choose it.\\n\\nContext: We could certainly slow the aging process down if it had to work its way through Congress .\\nQuestion: How long did it take for it to work its way?\\nOptions:\\nA. several years\\nB. 1 year\\nC. 8 months\\nD. several days\\nE. a few days\\nF. for hours\\nG. 2 days\\nAnswer:\\n',\n",
       " ['several years',\n",
       "  '1 year',\n",
       "  '8 months',\n",
       "  'several days',\n",
       "  'a few days',\n",
       "  'for hours',\n",
       "  '2 days'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 15\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt4.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A. for hours\\nC. 4 hours\\nF. 36 seconds\\n\\nExplanation:\\nBased on the context provided, it is mentioned that it took \"1 + hour\" to deliver to Chatham. This indicates that the delivery time is more than 1 hour but less than 2 hours. Therefore, option A. \"for hours\" is correct.\\n\\nOptions B, D, E, G, and H can be eliminated as they do not align with the given context. Option B suggests 8 hours, which is too long. Option D suggests 16 seconds, which is too short. Option E suggests 2 years, which is significantly longer than the given context. Options G and H suggest several or a few months, which is also much longer than the given context.\\n\\nOption C. 4 hours is a possible duration that falls within the range of \"1 + hour\" mentioned in the context. Therefore, it is a correct option.\\n\\nOption F. 36 seconds is not a plausible duration for a delivery to take, as it is too short. However, it is included as a correct option because it is possible that the mention of \"36 seconds\" could be related to another aspect of the context, such as the time it took for the driver to realize there was hair in the food.'],\n",
       " \"There is a question about the commonsense knowledge of event duration.\\nYou should answer the questions based on the context and select all correct options.\\nAfter each chosen option, explain why you choose it.\\n\\nContext: Took 1 + hour to deliver to Chatham , hair in food , driver did n't know area .\\nQuestion: How long does it take for to deliver to Chatham to take 1 + hour?\\nOptions:\\nA. for hours\\nB. 8 hours\\nC. 4 hours\\nD. 16 seconds\\nE. 2 years\\nF. 36 seconds\\nG. several months\\nH. a few months\\nAnswer:\\n\",\n",
       " ['for hours',\n",
       "  '8 hours',\n",
       "  '4 hours',\n",
       "  '16 seconds',\n",
       "  '2 years',\n",
       "  '36 seconds',\n",
       "  'several months',\n",
       "  'a few months'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 99\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt4.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B. a few hours\\nC. 1 hour'],\n",
       " \"According to the context, answer the questions and select all correct options.\\n\\nContext: It 's a nice , relaxed place to get stuff done and relax .\\nQuestion: How long does it take to relax?\\nOptions:\\nA. 15 hours\\nB. a few hours\\nC. 1 hour\\nD. 42 seconds\\nE. a few weeks\\nF. 8 years\\nG. 2 months\\n\",\n",
       " ['15 hours',\n",
       "  'a few hours',\n",
       "  '1 hour',\n",
       "  '42 seconds',\n",
       "  'a few weeks',\n",
       "  '8 years',\n",
       "  '2 months'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 25\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt2.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B. a few hours\\nC. 1 hour'],\n",
       " \"According to the context, answer the questions and select all correct options.\\n\\nContext: It 's a nice , relaxed place to get stuff done and relax .\\nQuestion: How long does it take to relax?\\nOptions:\\nA. 15 hours\\nB. a few hours\\nC. 1 hour\\nD. 42 seconds\\nE. a few weeks\\nF. 8 years\\nG. 2 months\\nAnswer:\\n\",\n",
       " ['15 hours',\n",
       "  'a few hours',\n",
       "  '1 hour',\n",
       "  '42 seconds',\n",
       "  'a few weeks',\n",
       "  '8 years',\n",
       "  '2 months'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 25\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt2.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The answer is D. for weeks.'],\n",
       " 'According to the context, answer the questions and select all correct options.\\n\\nContext: okay , I do nt have a review , but why in the hell would you name your business something that has the initials KKK .... is there something behind the scenes at this place ?\\nQuestion: How long does it take for me to have a review?\\nOptions:\\nA. 1 minute\\nB. a few minutes\\nC. 46 minutes\\nD. for weeks\\nE. 6 weeks\\nF. several weeks\\nG. 2 months\\nH. several months\\nAnswer:\\n',\n",
       " ['1 minute',\n",
       "  'a few minutes',\n",
       "  '46 minutes',\n",
       "  'for weeks',\n",
       "  '6 weeks',\n",
       "  'several weeks',\n",
       "  '2 months',\n",
       "  'several months'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt2.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Based on the context, it is not possible to determine the duration of time it would take for the person to have a review. Therefore, none of the options provided can be considered correct.'],\n",
       " 'There is a question about the commonsense knowledge of event duration.\\nYou should answer the questions based on the context and select all correct options.\\n\\nContext: okay , I do nt have a review , but why in the hell would you name your business something that has the initials KKK .... is there something behind the scenes at this place ?\\nQuestion: How long does it take for me to have a review?\\nOptions:\\nA. 1 minute\\nB. a few minutes\\nC. 46 minutes\\nD. for weeks\\nE. 6 weeks\\nF. several weeks\\nG. 2 months\\nH. several months\\nAnswer:\\n',\n",
       " ['1 minute',\n",
       "  'a few minutes',\n",
       "  '46 minutes',\n",
       "  'for weeks',\n",
       "  '6 weeks',\n",
       "  'several weeks',\n",
       "  '2 months',\n",
       "  'several months'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt3.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['C. for weeks'],\n",
       " \"There is a question about the commonsense knowledge of event duration.\\nYou should answer the questions based on the context and select all correct options.\\n\\nContext:  While we do n't have anything specific to announce today , Google and the Wikimedia Foundation are collaboratively evaluating creative ways to support Wikipedia.org and its community . \\nQuestion: How long does it take for Google and the Wikimedia Foundation to evaluate creative ways to support Wikipedia.org and its community?\\nOptions:\\nA. 12 weeks\\nB. 6 weeks\\nC. for weeks\\nD. several years\\nE. several decades\\nF. 30 minutes\\nG. a few seconds\\nAnswer:\\n\",\n",
       " ['12 weeks',\n",
       "  '6 weeks',\n",
       "  'for weeks',\n",
       "  'several years',\n",
       "  'several decades',\n",
       "  '30 minutes',\n",
       "  'a few seconds'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 56\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt3.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Based on the context, the correct options for how long it took to name something at a carnival that comes on a stick could be:\\n\\nB. almost instantly\\nC. several seconds'],\n",
       " 'There is a question about the commonsense knowledge of event duration.\\nYou should answer the questions based on the context and select all correct options.\\n\\nContext: Name something you find at a carnival that comes on a stick ?\\nQuestion: How long did it take to name?\\nOptions:\\nA. 50 seconds\\nB. almost instantly\\nC. several seconds\\nD. 4 days\\nE. for hours\\nF. 18 hours\\nG. 4 weeks\\nAnswer:\\n',\n",
       " ['50 seconds',\n",
       "  'almost instantly',\n",
       "  'several seconds',\n",
       "  '4 days',\n",
       "  'for hours',\n",
       "  '18 hours',\n",
       "  '4 weeks'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 89\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt3.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The correct answer is G. a few months.'],\n",
       " \"There is a question about the commonsense knowledge of event duration.\\nYou should answer the questions based on the context and select all correct options.\\n\\nContext: By the time a man is wise enough to watch his step , he 's too old to go anywhere .\\nQuestion: How long does it take for a man to watch his step?\\nOptions:\\nA. 54 seconds\\nB. 50 seconds\\nC. 56 seconds\\nD. a few days\\nE. 10 months\\nF. 20 weeks\\nG. a few months\\nAnswer:\\n\",\n",
       " ['54 seconds',\n",
       "  '50 seconds',\n",
       "  '56 seconds',\n",
       "  'a few days',\n",
       "  '10 months',\n",
       "  '20 weeks',\n",
       "  'a few months'],\n",
       " ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 125\n",
    "c,q,o = datas[n]['context'], datas[n]['question'], convert_options_to_options(datas[n]['options'])\n",
    "input = prompt3.format(c, q, o)\n",
    "gpt_decoder(input), input, datas[n]['options'], datas[n]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_f1 = load_jsonl('./durationqa_f1_timebench.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': '1_1_7',\n",
       " 'context': 'Okay , FIRST , you have posted a question about an American movie , set in Mexico , in the Dining Out in Argentina category .',\n",
       " 'question': 'How long did it take for them to post?',\n",
       " 'option': 'several minutes',\n",
       " 'label': 'yes'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas_f1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt01 = \"\"\"There is a pair of question and answer. \n",
    "You need to determine if the answer is correct based on the context.\n",
    "\n",
    "Context: {}\n",
    "Question: {}\n",
    "Answer: {}\n",
    "A. It is correct\n",
    "B. It is wrong\"\"\"\n",
    "\n",
    "prompt02 = \"\"\"There is a pair of question and answer. \n",
    "You need to determine if the answer is correct.\n",
    "\n",
    "Context: {}\n",
    "Question: {}\n",
    "Answer: {}\n",
    "A. It is correct\n",
    "B. It is wrong\"\"\"\n",
    "\n",
    "prompt03 = \"\"\"There is a context with a question and an answer to the question.\n",
    "You need to determine if the answer is correct or not.\n",
    "\n",
    "Context: {}\n",
    "Question: {}\n",
    "Answer: {}\n",
    "A. The answer is correct\n",
    "B. The answer is wrong\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B. It is wrong'], ['B. It is wrong'], ['B. The answer is wrong'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_decoder(prompt01.format(datas_f1[0]['context'], datas_f1[0]['question'], datas_f1[0]['option'])), \\\n",
    "    gpt_decoder(prompt02.format(datas_f1[0]['context'], datas_f1[0]['question'], datas_f1[0]['option'])), \\\n",
    "        gpt_decoder(prompt03.format(datas_f1[0]['context'], datas_f1[0]['question'], datas_f1[0]['option']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_decoder(prompt01.format(datas_f1[0]['context'], datas_f1[0]['question'], datas_f1[0]['option'])), \\\n",
    "    gpt_decoder(prompt02.format(datas_f1[0]['context'], datas_f1[0]['question'], datas_f1[0]['option']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is a pair of question and answer. \\nYou need to determine if the answer is correct based on the context.\\n\\nContext: Okay , FIRST , you have posted a question about an American movie , set in Mexico , in the Dining Out in Argentina category .\\nQuestion: How long did it take for them to post?\\nAnswer: several minutes\\nA. It is correct\\nB. It is wrong'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt01.format(datas_f1[0]['context'], datas_f1[0]['question'], datas_f1[0]['option'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is a pair of question and answer. \\nYou need to determine if the answer is correct based on the context.\\n\\nContext: Okay , FIRST , you have posted a question about an American movie , set in Mexico , in the Dining Out in Argentina category .\\nQuestion: How long did it take for them to post?\\nAnswer: several minutes\\nA. It is correct\\nB. It is wrong'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt01.format(datas_f1[0]['context'], datas_f1[0]['question'], datas_f1[0]['option'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
